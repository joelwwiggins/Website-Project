{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import chardet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data\n",
    "#Questions to answer:\n",
    "#Who is the goat? Who has the highest average similarity score for all jobs?\n",
    "#Who is best fit for a job?\n",
    "\n",
    "jobs_import=pd.read_csv('data job posts.csv',encoding = \"utf-8\")\n",
    "resume_import=pd.read_csv('UpdatedResumeDataSet - Copy.csv',engine=\"python\", encoding=\"utf-8\")\n",
    "# #Why won't you give me the correct formatting????\n",
    "# path = 'UpdatedResumeDataSet - Copy.csv'\n",
    "# with open(path, mode='rb') as f:\n",
    "#     binary = f.read()\n",
    "#     code = chardet.detect(binary)['encoding']\n",
    "#     print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science',\n",
       " 'Data Science',\n",
       " 'Data Science',\n",
       " 'Data Science',\n",
       " 'Data Science']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_category_list=list(resume_import.iloc[:5,0])\n",
    "resume_category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMERIA Investment Consulting Company',\n",
       " 'International Research & Exchanges Board (IREX)',\n",
       " 'Caucasus Environmental NGO Network (CENN)',\n",
       " 'Manoff Group',\n",
       " 'Yerevan Brandy Company']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_list=list(jobs_import.iloc[:5,3])\n",
    "company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all non utf-8 characters\n",
    "resume_import_clean=resume_import.replace('[^a-zA-Z\\d\\_.]+',' ',regex=True)\n",
    "jobs_import_clean=jobs_import.replace('[^a-zA-Z\\d\\_.]+',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cosign similary to see how similar all job postings are to other job postings\n",
    "post=jobs_import_clean['jobpost']\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(post)\n",
    "cosine_sim = cosine_similarity(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post=jobs_import_clean['jobpost']\n",
    "# cv = CountVectorizer()\n",
    "# count_matrix = cv.fit_transform(post)\n",
    "# cosine_sim = cosine_similarity(count_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cosign similary to see how similar all resumes are to other resumes\n",
    "resume_desc=resume_import_clean['Resume']\n",
    "count_matrix_resume = cv.fit_transform(resume_desc)\n",
    "cosine_sim_resume = cosine_similarity(count_matrix_resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack job posts in same column as resume in data frame so that cosign similarity of everything can be determined\n",
    "job_resume_stack=pd.concat([resume_desc,post],ignore_index=True)\n",
    "job_resume_stackdf=pd.DataFrame(job_resume_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate cosign similarity of everything\n",
    "job_resume_stack_info=job_resume_stackdf.iloc[:,0]\n",
    "count_matrix_stack = cv.fit_transform(job_resume_stack_info)\n",
    "cosine_sim_stack = cosine_similarity(count_matrix_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001A6DE5625C0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001A6DE545EF0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the stack is a data frame\n",
    "cosine_sim_stackdf=pd.DataFrame(cosine_sim_stack)\n",
    "#Create stack dataframe to hold stats\n",
    "stack=pd.DataFrame()\n",
    "# Add mean cosign similarity of every row into a column named \"mean\"\n",
    "cosine_sim_stackdf['mean']=cosine_sim_stackdf.mean(axis=1)\n",
    "#Comaring resumes to jobs\n",
    "stack['resume_mean']=cosine_sim_stackdf.iloc[19002:,:19002].mean(axis=1)\n",
    "#comparing all jobs to jobs\n",
    "#Not sure why job_mean doesn't plot here. Can be corrected by taking out on of the historgrams.\n",
    "stack['job_mean']=cosine_sim_stackdf.iloc[0:19001,0:19001].mean(axis=1)\n",
    "stack.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a6e1649828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack['job_mean']=cosine_sim_stackdf.iloc[19002:,:19002].max(axis=1)\n",
    "stack['resume_mean'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_mean</th>\n",
       "      <th>job_mean</th>\n",
       "      <th>resume_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19040</th>\n",
       "      <td>0.712837</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.999586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19045</th>\n",
       "      <td>0.716368</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.999449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19266</th>\n",
       "      <td>0.684906</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.999263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19641</th>\n",
       "      <td>0.717245</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.999021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       resume_mean  job_mean  resume_max\n",
       "19040     0.712837  0.999586    0.999586\n",
       "19045     0.716368  0.999449    0.999449\n",
       "19266     0.684906  0.999263    0.999263\n",
       "19641     0.717245  0.999021    0.999021"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Who is the best fit for specific job?\n",
    "like_a_glove=stack[stack['resume_max']>.999]\n",
    "like_a_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_mean</th>\n",
       "      <th>job_mean</th>\n",
       "      <th>resume_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>0.741292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19875</th>\n",
       "      <td>0.740877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       resume_mean  job_mean  resume_max\n",
       "19308     0.741292       NaN    0.915805\n",
       "19875     0.740877       NaN    0.955529"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highers average similary score doesn't have the highest max similarity.  May need to look by job description\n",
    "cosine_simdf=pd.DataFrame(cosine_sim)\n",
    "goat=stack[stack['resume_mean']>.74]\n",
    "goat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Personal Skills Ability to quickly grasp technical aspects and willingness to learn High energy levels Result oriented. Education Details January 2018 Master of Engineering Computer Technology Application Bhopal Madhya Pradesh Truba Institute of Engineering Information Technology January 2010 B.E. computer science Bhopal Madhya Pradesh RKDF Institute of Science and Technology College of Engineering January 2006 Polytechnic Information Technology Vidisha Madhya Pradesh SATI Engineering College in Vidisha January 2003 M.tech Thesis Detail BMCH School in Ganj basoda Data science I have six month experience in Data Science. Key Skills Experience in Machine Learning Deep Leaning NLP Python SQL Web Scraping Good knowledge in computer subjects and ability to update Skill Details Experience in Machine Learning Deep Learning NLP Python SQL Web Crawling HTML CSS. Exprience Less than 1 year monthsCompany Details company RNT.AI Technology Solution description Text classification using Machine learning Algorithms with python. Practical knowledge of Deep learning algorithms such as Recurrent Neural Networks RNN . Develop custom data models and algorithms to apply to dataset Experience with Python packages like Pandas Scikit learn Tensor Flow Numpy Matplotliv NLTK. Comfort with SQL MYSQL Sentiment analysis. Apply leave Dataset using classification technique like Tf idf LSA with cosine similarity using Machine learning Algorithms. Web crawling using Selenium web driver and Beautiful Soup with python. company Life Insurance Corporation of India Bhopal description Explaining policy features and the benefits Updated knowledge of life insurance products and shared with customers'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This mf'r has a background in cosign similarity projects and also has the highest resume to job similarity!!!!\n",
    "resume_desc.iloc[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': 'Data Science',\n",
       " 'Resume': 'Skills Programming Languages Python pandas numpy scipy scikit learn matplotlib Sql Java JavaScript JQuery. Machine learning Regression SVM Na ve Bayes KNN Random Forest Decision Trees Boosting techniques Cluster Analysis Word Embedding Sentiment Analysis Natural Language processing Dimensionality reduction Topic Modelling LDA NMF PCA Neural Nets. Database Visualizations Mysql SqlServer Cassandra Hbase ElasticSearch D3.js DC.js Plotly kibana matplotlib ggplot Tableau. Others Regular Expression HTML CSS Angular 6 Logstash Kafka Python Flask Git Docker computer vision Open CV and understanding of Deep learning.Education Details Data Science Assurance Associate Data Science Assurance Associate Ernst Young LLP Skill Details JAVASCRIPT Exprience 24 months jQuery Exprience 24 months Python Exprience 24 monthsCompany Details company Ernst Young LLP description Fraud Investigations and Dispute Services Assurance TECHNOLOGY ASSISTED REVIEW TAR Technology Assisted Review assists in accelerating the review process and run analytics and generate reports. Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain this tool implements predictive coding and topic modelling by automating reviews resulting in reduced labor costs and time spent during the lawyers review. Understand the end to end flow of the solution doing research and development for classification models predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool. TAR assists in predictive coding topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify red flags and fraud related issues. Tools Technologies Python scikit learn tfidf word2vec doc2vec cosine similarity Na ve Bayes LDA NMF for topic modelling Vader and text blob for sentiment analysis. Matplot lib Tableau dashboard for reporting. MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS USA CLIENTS TEXT ANALYTICS MOTOR VEHICLE CUSTOMER REVIEW DATA Received customer feedback survey data for past one year. Performed sentiment Positive Negative Neutral and time series analysis on customer comments across all 4 categories. Created heat map of terms by survey category based on frequency of words Extracted Positive and Negative words across all the Survey categories and plotted Word cloud. Created customized tableau dashboards for effective reporting and visualizations. CHATBOT Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation reservation options and so on. This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer. This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant recommended questions. Tools Technologies Python Natural language processing NLTK spacy topic modelling Sentiment analysis Word Embedding scikit learn JavaScript JQuery SqlServer INFORMATION GOVERNANCE Organizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk. Scan data from multiple sources of formats and parse different file formats extract Meta data information push results for indexing elastic search and created customized interactive dashboards using kibana. Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant Outdated or Trivial. Preforming full text search analysis on elastic search with predefined methods which can tag as PII personally identifiable information social security numbers addresses names etc. which frequently targeted during cyber attacks. Tools Technologies Python Flask Elastic Search Kibana FRAUD ANALYTIC PLATFORM Fraud Analytics and investigative platform to review all red flag cases. FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems. It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics Tools Technologies HTML JavaScript SqlServer JQuery CSS Bootstrap Node.js D3.js DC.js'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=jobs_import_clean.to_dict('records')\n",
    "B=resume_import_clean.to_dict('records')\n",
    "B[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data into mongodb\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "conn = \"mongodb+srv://abc:1234@cluster0.7hm4r.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\"\n",
    "# conn = \"mongodb://abc:1234@cluster0.7hm4r.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install pymongo[srv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up tables in db\n",
    "db = client.job_resume\n",
    "resume = db.resume\n",
    "job=db.job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x28313d965c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert data to tables\n",
    "job.insert_many(A)\n",
    "resume.insert_many(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['cluster0-shard-00-00.7hm4r.mongodb.net:27017', 'cluster0-shard-00-01.7hm4r.mongodb.net:27017', 'cluster0-shard-00-02.7hm4r.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='atlas-qg2x3q-shard-0', ssl=True), 'job_resume'), 'resume.0.text')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_request=job.find()\n",
    "job_request_list=list(job_request)\n",
    "five_job=job_request_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_limited=db.five_job\n",
    "# job_limited.insert_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_request=resume.find()\n",
    "resume_request_list=list(resume_request)\n",
    "five_resume=resume_request_list[:5]\n",
    "five_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_post=post.iloc[:5]\n",
    "five_resume_desc=resume_desc.iloc[:5]\n",
    "short_stack=pd.concat([five_post,five_resume_desc],ignore_index=True)\n",
    "short_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_postdf=pd.DataFrame(five_post)\n",
    "five_resume_descdf=pd.DataFrame(five_resume_desc)\n",
    "count_matrix_five_postdf = cv.fit_transform(five_postdf)\n",
    "count_matrix_five_resume_descdf = cv.fit_transform(five_resume_descdf)\n",
    "cosine_sim_short_stack=pd.concat([five_post,five_resume_desc],ignore_index=True)\n",
    "cosine_sim_short_stackdf=pd.DataFrame(cosine_sim_short_stack)\n",
    "#fit_transform the short list data\n",
    "cosine_sim_short_stackdf_fit=cv.fit_transform(short_stack)\n",
    "\n",
    "cosine_sim_short_stack_score=cosine_similarity(cosine_sim_short_stackdf_fit)\n",
    "cosine_sim_short_stack_score_df=pd.DataFrame(cosine_sim_short_stack_score)\n",
    "cosine_sim_short_stack_score_df\n",
    "short_cos=cosine_sim_short_stack_score_df.iloc[5:,:5]\n",
    "short_cos\n",
    "# cosine_sim_short_stack = cosine_similarity(count_matrix_five_postdf,count_matrix_five_resume_descdf)\n",
    "# cosine_sim_short_stackdf=pd.DataFrame(cosine_sim_short_stack)\n",
    "# cosine_sim_short_stackdf.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = short_cos.columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_cos.columns=short_cos.columns.astype(str)\n",
    "short_cos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create database\n",
    "job_limited=db.five_job\n",
    "#Convert data for database\n",
    "\n",
    "\n",
    "\n",
    "C=short_cos.to_dict('Records')\n",
    "\n",
    "job_limited.insert_many(C)\n",
    "job_limited.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6188657ee80ddef3047649e5'),\n",
       " 'data': 11,\n",
       " 'analysis': 8,\n",
       " 'information': 8,\n",
       " 'review': 7,\n",
       " 'python': 6,\n",
       " 'fraud': 6,\n",
       " 'analytics': 6,\n",
       " 'topic': 5,\n",
       " 'modelling': 5,\n",
       " 'js': 5,\n",
       " 'platform': 5,\n",
       " 'javascript': 4,\n",
       " 'jquery': 4,\n",
       " 'word': 4,\n",
       " 'sentiment': 4,\n",
       " 'tool': 4,\n",
       " 'text': 4,\n",
       " 'tools': 4,\n",
       " 'technologies': 4,\n",
       " 'questions': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from numpy.core.function_base import logspace\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "# app.config[\"MONGO_URI\"] = \"mongodb+srv://abc:1234@cluster0.7hm4r.mongodb.net/job_resume?retryWrites=true&w=majority\"\n",
    "# mongo = PyMongo(app)\n",
    "# # conn = \"mongodb+srv://abc:1234@cluster0.7hm4r.mongodb.net/job_resume?retryWrites=true&w=majority\"\n",
    "# client = PyMongo.MongoClient(conn)\n",
    "# db = client.job_resume\n",
    "\n",
    "conn = \"mongodb+srv://abc:1234@cluster0.7hm4r.mongodb.net/job_resume?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.job_resume\n",
    "d = db.cos_sim.find({})\n",
    "a = [x for x in d]\n",
    "job_resume = a[0]\n",
    "\n",
    "word_mix=db.resume_word_count.find({})\n",
    "a2=[x for x in word_mix]\n",
    "all_word_mix=a2[0]\n",
    "all_word_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def word_top10(words):\n",
    "    d2=all_word_mix\n",
    "    word_df=pd.DataFrame([d2[words]]).T\n",
    "    word_df.columns=['word_count']\n",
    "    d3=word_df.sort_values('word_count',ascending=False)\n",
    "    return d3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count\n",
       "0          11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_top10('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55e9a13aadb3219695851578b9bfbba67486e5841a37aff088bdd8c6a920c21e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
